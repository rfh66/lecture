## Reading questions

The first two questions are questions from last time, but worth
revisiting.  These are up rather late, but do what you can, and come
with questions for class!

1.  The class cluster consists of eight nodes and fifteen Xeon Phi
    accelerator boards.  Based on an online search for information on
    these systems, what do you think is the theoretical peak flop rate
    (double-precision floating point operations per second)?  Show how
    you computed this, and give URLs for where you got the parameters
    in your calculation.  (We will return to this question again after
    we cover some computer architecture.)
    
    Each of the 8 nodes has 12 cores (96 cores there).  From this site:
    http://ark.intel.com/products/83352/Intel-Xeon-Processor-E5-2620-v3-15M-Cache-2_40-GHz
    Each core has 12 threads and 4 memory channels, allowing for 48 flop per clock on a single core, or 4608 flop/clock on all 96 cores.
    
    Each Xeon Phi board has 60 cores, for 900 total.  Each core has 16 memory channels, allowing for 16 flop/clock on a single core, or 14400 on all 900.  Between the Xeon Phi boards and the 8 nodes, this is 19008 flop/clock (both numbers can be added because the clock rates are the same).  Multiplying by the 1.053 GHz clock rate gives 20.0 teraflop/s.
    
2.  What is the approximate theoretical peak flop rate for your own machine?
i5-2540m processor:
http://ark.intel.com/products/50072/Intel-Core-i5-2540M-Processor-3M-Cache-up-to-3_30-GHz
<2 cores>*<4 threads> = 8 flop/clock.
Multiplying by clock freq. (3.3 GHz) gives 26.4 gigaflop/s

3.  Suppose there are t tasks that can be executed in a pipeline
    with p stages.  What is the speedup over serial execution of the
    same tasks?

4.  Consider the following list of tasks (assume they can't be pipelined):

      compile GCC (1 hr)
      compile OpenMPI (0.5 hr) - depends on GCC
      compile OpenBLAS (0.25 hr) - depends on GCC
      compile LAPACK (0.5 hr) - depends on GCC and OpenBLAS
      compile application (0.5 hr) - depends on GCC, OpenMPI,
        OpenBLAS, LAPACK

    What is the minimum serial time between starting to compile and having
    a compiled application?  What is the minimum parallel time given
    an arbitrary number of processors?
    
    GCC compile from t=0 to t=1h
    OpenMPI compile from t=1h to t=1.5h
    OpenBLAS from t=1h to t=1.25hr
    LAPACK from t=1.25h to 1.75h
    application compile from 1.75h to 2.25h
    ==>2.25 h

5.  Clone the membench repository from GitHub:

       git clone git@github.com:cornell-cs5220-f15/membench.git

    On your own machine, build `membench` and generate the associated
    plots; for many of you, this should be as simple as typing `make`
    at the terminal (though I assume you have Python with pandas and
    Matplotlib installed; see also the note about Clang and OpenMP
    in the leading comments of the Makefile).  Look at the output file
    timings-heat.pdf; what can you tell about the cache architecture
    on your machine from the plot?

6.  From the cloned repository, check out the totient branch:

       git checkout totient

    You may need to move generated files out of the way to do this.
    If you prefer, you can also look at the files on GitHub.  Either
    way, repeat the exercise of problem 5.  What can you tell about
    the cache architecture of the totient nodes?

7.  Implement the following three methods of computing the centroid
    of a million two-dimensional coordinates (double precision).
    Time and determine which is faster:

    a.  Store an array of (x,y) coordinates; loop i and simultaneously
        sum the xi and yi

    b.  Store an array of (x,y) coordinates; loop i and sum the xi,
        then sum the yi in a separate loop

    c.  Store the xi in one array, the yi in a second array.
        Sum the xi, then sum the yi.

    I recommend doing this on the class cluster using the Intel
    compiler.  To do this, run "module load cs5220" and run (e.g.)

Time for each method (s)
0.037720
0.069840
0.0649

// ConsoleApplication2.cpp : Defines the entry point for the console application.
//

#include "stdafx.h"
#include <fstream>
#include <random>
#include <time.h>
#include <chrono>
#define N 10000000
using namespace std;
using namespace std::chrono;

struct numpair
{
	double x; double y;
};

int _tmain(int argc, _TCHAR* argv[])
{
	// initialize random values
	
	numpair *pairs=new numpair[N]();
	double *xs=new double[N];
	double *ys=new double[N];

		for (int i = 0; i < N; i++)
		{
			pairs[i].x = static_cast <double> (rand()) / static_cast <double> (RAND_MAX);
			pairs[i].y = static_cast <double> (rand()) / static_cast <double> (RAND_MAX);
			xs[i] = pairs[i].x;
			ys[i] = pairs[i].y;
		}
	// method 1
	clock_t start = clock();
	double xtot = 0;
	double ytot = 0;
	for (int j = 0; j < 100; j++)
	{
		xtot = 0;
		ytot = 0;
		for (int i = 0; i < N; i++)
		{
			xtot += pairs[i].x;
			ytot += pairs[i].y;
		}
	}
	xtot /= N;
	ytot /= N;
	printf("%f\t%f\n", xtot, ytot);
	printf("%f\n", float(clock() - start) / (100*CLOCKS_PER_SEC));
	// method 2
	start = clock();
	for (int j = 0; j < 100; j++)
	{
		xtot = 0;
		ytot = 0;
		for (int i = 0; i < N; i++)
		{
			xtot += pairs[i].x;
		}
		for (int i = 0; i < N; i++)
		{
			ytot += pairs[i].y;
		}
	}
	xtot /= N;
	ytot /= N;
	printf("%f\t%f\n", xtot, ytot);
	printf("%f\n", float(clock() - start) / (100*CLOCKS_PER_SEC));
	// method 3
	start = clock();
	for (int j = 0; j < 100; j++)
	{
		xtot = 0;
		ytot = 0;
		for (int i = 0; i < N; i++)
		{
			xtot += xs[i];
		}
		for (int i = 0; i < N; i++)
		{
			ytot += ys[i];
		}
	}
	xtot /= N;
	ytot /= N;
	printf("%f\t%f\n", xtot, ytot);
	printf("%f\n", float(clock() - start) / (100*CLOCKS_PER_SEC));
}


